LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name    | Type                 | Params | Mode
---------------------------------------------------------
0 | model   | ProteinEditFlowModel | 742 M  | train
1 | loss_fn | EditFlowsLoss        | 0      | train
---------------------------------------------------------
91.6 M    Trainable params
651 M     Non-trainable params
742 M     Total params
2,970.760 Total estimated model params size (MB)
170       Modules in train mode
574       Modules in eval mode
Epoch 0:   0%|                                                                           | 0/11143 [00:00<?, ?it/s]
/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:527: Found 574 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.
Traceback (most recent call last):
  File "/usr/project/xtmp/mth45/Documents/programmable_biology_group/EditFlows/flow_matching/editflows/train.py", line 146, in <module>
    main()
  File "/usr/project/xtmp/mth45/Documents/programmable_biology_group/EditFlows/flow_matching/editflows/train.py", line 142, in main
    trainer.fit(editflow, train_dataloader, val_dataloader)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/amp.py", line 76, in optimizer_step
    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
  File "/usr/project/xtmp/mth45/Documents/programmable_biology_group/EditFlows/flow_matching/editflows/model/base_models.py", line 480, in training_step
    lam_ins, logits_ins, lam_del, lam_sub, logits_sub, z_t, z_1, x_t, mask, weight = self.preparation(x_1)
  File "/usr/project/xtmp/mth45/Documents/programmable_biology_group/EditFlows/flow_matching/editflows/model/base_models.py", line 471, in preparation
    lam_ins, logits_ins, lam_del, lam_sub, logits_sub = self.model(x_t=x_t, mask=mask,t=t)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/mth45/Documents/programmable_biology_group/EditFlows/flow_matching/editflows/model/base_models.py", line 269, in forward
    h = blk(h, key_padding_mask=(~mask))
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/mth45/Documents/programmable_biology_group/EditFlows/flow_matching/editflows/model/base_models.py", line 177, in forward
    x = x + self.attn(self.norm1(x), key_padding_mask=key_padding_mask)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/mth45/Documents/programmable_biology_group/EditFlows/flow_matching/editflows/model/base_models.py", line 150, in forward
    attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_head)  # (B, h, L, L)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.06 GiB. GPU 0 has a total capacity of 47.41 GiB of which 291.31 MiB is free. Including non-PyTorch memory, this process has 47.12 GiB memory in use. Of the allocated memory 45.01 GiB is allocated by PyTorch, and 1.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/usr/project/xtmp/mth45/Documents/programmable_biology_group/EditFlows/flow_matching/editflows/train.py", line 146, in <module>
    main()
  File "/usr/project/xtmp/mth45/Documents/programmable_biology_group/EditFlows/flow_matching/editflows/train.py", line 142, in main
    trainer.fit(editflow, train_dataloader, val_dataloader)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/amp.py", line 76, in optimizer_step
    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
  File "/usr/project/xtmp/mth45/Documents/programmable_biology_group/EditFlows/flow_matching/editflows/model/base_models.py", line 480, in training_step
    lam_ins, logits_ins, lam_del, lam_sub, logits_sub, z_t, z_1, x_t, mask, weight = self.preparation(x_1)
  File "/usr/project/xtmp/mth45/Documents/programmable_biology_group/EditFlows/flow_matching/editflows/model/base_models.py", line 471, in preparation
    lam_ins, logits_ins, lam_del, lam_sub, logits_sub = self.model(x_t=x_t, mask=mask,t=t)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/mth45/Documents/programmable_biology_group/EditFlows/flow_matching/editflows/model/base_models.py", line 269, in forward
    h = blk(h, key_padding_mask=(~mask))
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/mth45/Documents/programmable_biology_group/EditFlows/flow_matching/editflows/model/base_models.py", line 177, in forward
    x = x + self.attn(self.norm1(x), key_padding_mask=key_padding_mask)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/project/xtmp/mth45/miniforge3/envs/EditFlows/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/mth45/Documents/programmable_biology_group/EditFlows/flow_matching/editflows/model/base_models.py", line 150, in forward
    attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_head)  # (B, h, L, L)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.06 GiB. GPU 0 has a total capacity of 47.41 GiB of which 291.31 MiB is free. Including non-PyTorch memory, this process has 47.12 GiB memory in use. Of the allocated memory 45.01 GiB is allocated by PyTorch, and 1.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
